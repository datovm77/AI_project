import streamlit as st
import asyncio
import nest_asyncio
import os
import json
import base64
import pdfplumber
import docx
from datetime import datetime
from typing import List, Dict, Any, Tuple, AsyncGenerator
from dotenv import load_dotenv
from openai import AsyncOpenAI
try:
    import search_service
except ImportError:
    st.error("æ‰¾ä¸åˆ° search_service.pyï¼Œè¯·ç¡®ä¿è¯¥æ–‡ä»¶åœ¨åŒä¸€ç›®å½•ä¸‹ã€‚")

# streamlit run agent1.0.py
# ==========================================
# 1. âš™ï¸ é…ç½®ä¸åˆå§‹åŒ–
# ==========================================
load_dotenv()  #å¯¼å…¥secrets
nest_asyncio.apply()  # å…è®¸åµŒå¥—äº‹ä»¶å¾ªç¯

PROFILE_PATH = "profile.txt"
HISTORY_PATH = "history.json"

API_KEY = st.secrets["API_KEY"]
BASE_URL = "https://openrouter.ai/api/v1"

# åˆå§‹åŒ–å®¢æˆ·ç«¯
client = AsyncOpenAI(api_key=API_KEY, base_url=BASE_URL)

# ã€é‡è¦é…ç½®ã€‘æ¨¡å‹è§’è‰²åˆ†é…
# è¿™é‡Œçš„æ¨¡å‹é€‰æ‹©å†³å®šäº†æ˜¯å¦æ”¯æŒå¤šæ¨¡æ€ (Vision)
MODEL_CONFIG = {
    "librarian": "google/gemini-3-flash-preview", 
    "reviewer": "google/gemini-3-flash-preview",
    "architect": "google/gemini-3-flash-preview",
    "mentor": "anthropic/claude-opus-4.5"          
}

# ==========================================
# 2. ğŸ› ï¸ æ ¸å¿ƒå·¥å…·å‡½æ•° (Utils)
# ==========================================

def encode_image_to_base64(image_bytes: bytes) -> str:
    """
    [å·¥å…·] å°†å›¾ç‰‡äºŒè¿›åˆ¶æµè½¬æ¢ä¸º Base64 å­—ç¬¦ä¸²ã€‚
    ç”¨äºå°†å›¾ç‰‡ä¼ ç»™æ”¯æŒ Vision çš„ LLMã€‚
    """
    return base64.b64encode(image_bytes).decode('utf-8')

def parse_uploaded_file(uploaded_file) -> Dict[str, Any]:
    """
    [æ ¸å¿ƒå·¥å…·] é€šç”¨æ–‡ä»¶è§£æå·¥å‚ã€‚
    è¾“å…¥: Streamlit ä¸Šä¼ æ–‡ä»¶å¯¹è±¡
    è¾“å‡º: å­—å…¸ {'filename':..., 'type': 'code'/'document'/'image'/'error', 'content':...}
    """
    file_type = uploaded_file.name.split('.')[-1].lower()
    result = {
        "filename": uploaded_file.name,
        "type": "unknown",
        "content": ""
    }

    try:
        if file_type == 'pdf':
            with pdfplumber.open(uploaded_file) as pdf:
                text_parts = []
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:  # âœ… æ£€æŸ¥æ˜¯å¦ä¸º None
                        text_parts.append(page_text)
                text = '\n'.join(text_parts)
            result["type"] = "document"
            result["content"] = text if text else "[PDF æ— æ³•æå–æ–‡æœ¬ï¼Œå¯èƒ½æ˜¯æ‰«æç‰ˆ]"

        elif file_type == 'docx':
            doc = docx.Document(uploaded_file)
            text = "\n".join(para.text for para in doc.paragraphs)
            result["type"] = "document"
            result["content"] = text

        elif file_type in ['txt', 'c', 'cpp', 'py', 'java', 'md', 'js', 'ts', 'go', 'rs']:
            text = uploaded_file.read().decode("utf-8", errors='ignore')
            result["type"] = "code"
            result["content"] = text

        elif file_type in ['png', 'jpg', 'jpeg', 'gif', 'webp']:
            bytes_data = uploaded_file.getvalue()
            result["type"] = "image"
            result["content"] = encode_image_to_base64(bytes_data)

    except Exception as e:
        result["type"] = "error"
        result["content"] = f"è¯»å–æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}"

    return result



async def search_web_tool(query: str) -> str:
    """
    [AI æ¥å£] ç»Ÿä¸€å°è£…çš„ LLM è°ƒç”¨å‡½æ•° (Generator)ã€‚
    """
    print(f"ğŸ” [Agent] æ­£åœ¨è°ƒç”¨æœç´¢å·¥å…·ï¼Œå…³é”®è¯: {query} ...")
    
    try:
        raw_results = await asyncio.to_thread(search_service.search_for_keyword, query)
        
        if not raw_results:
            return f"ã€æœç´¢ç»“æœã€‘å…³äº '{query}' æœªæ‰¾åˆ°æœ‰æ•ˆçš„ç½‘ç»œä¿¡æ¯ã€‚"

        # å°† JSON å¯¹è±¡æ‹¼æ¥æˆæ¸…æ™°çš„æ–‡æœ¬æŠ¥å‘Šä¾› LLM é˜…è¯»
        formatted_report = f"ä»¥ä¸‹æ˜¯å…³äº '{query}' çš„è”ç½‘æœç´¢ç»“æœæ±‡æ€»ï¼š\n\n"
        
        for idx, item in enumerate(raw_results):
            # å®¹é”™è·å–å­—æ®µï¼Œé˜²æ­¢æŸäº›å­—æ®µç¼ºå¤±
            title = item.get('title', 'æœªçŸ¥æ ‡é¢˜')
            url = item.get('source_url', '#')
            summary = item.get('summary', 'æš‚æ— æ‘˜è¦')
            key_points = item.get('key_points', [])
            code_snippets = item.get('code_snippets', [])

            formatted_report += f"--- æ¥æº [{idx + 1}] : {title} ---\n"
            formatted_report += f"é“¾æ¥: {url}\n"
            formatted_report += f"æ‘˜è¦: {summary}\n"
            
            if key_points:
                formatted_report += "å…³é”®ç‚¹:\n"
                for point in key_points:
                    formatted_report += f"   - {point}\n"
            
            if code_snippets:
                formatted_report += "ç›¸å…³ä»£ç ç‰‡æ®µ:\n"
                for code in code_snippets:
                    formatted_report += f"```\n{code[:500]}...\n```\n"
            
            formatted_report += "\n"

        return formatted_report

    except Exception as e:
        error_msg = f"æœç´¢å·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"
        print(error_msg)
        return error_msg

async def call_ai_chat(model: str, system_prompt: str, user_content: str, image_base64_list: List[str] = None):
    """
    [AI æ¥å£] ç»Ÿä¸€å°è£…çš„ LLM è°ƒç”¨å‡½æ•°ã€‚
    """
    messages = [
        {"role": "system", "content": system_prompt}
    ]

    if not image_base64_list:
        messages.append({"role": "user", "content": user_content})
    else:
        content_payload = []
        if user_content:
            content_payload.append({"type": "text", "text": user_content})
            
        # æ·»åŠ å›¾ç‰‡
        for img_b64 in image_base64_list:
            content_payload.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/jpeg;base64,{img_b64}" 
                }
            })
            
        messages.append({"role": "user", "content": content_payload})

    try:
        # 3. å‘èµ·å¼‚æ­¥è°ƒç”¨
        response = await client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=0.7,
            stream=True 
        )
        async for chunk in response:
            content = chunk.choices[0].delta.content
            if content:
                yield content

    except Exception as e:
        yield f"[Aiè°ƒç”¨å¤±è´¥]:{str(e)}"
# ==========================================
# 3. Agent æ ¸å¿ƒé€»è¾‘ (Agents)
# ==========================================

# --- Phase 1: é¢„å¤„ç† ---

async def agent_librarian(uploaded_files) -> Dict[str, Any]:
    """
    [Librarian - æ¡£æ¡ˆç®¡ç†å‘˜]
    èŒè´£ï¼šæ¸…æ´—æ•°æ®ï¼Œåˆ†ç±»æ•´ç†ï¼Œä¸è¿›è¡Œæ·±åº¦åˆ†æã€‚
    """
    # TODO:
    # 1. éå† uploaded_files
    # 2. è°ƒç”¨ parse_uploaded_file è§£ææ¯ä¸ªæ–‡ä»¶
    # 3. å°†ç»“æœåˆ†ç±»æ”¾å…¥ list: codes[], docs[], images[]
    # 4. è¿”å›ç»“æ„åŒ–å­—å…¸ structured_context

    #1.context å­—å…¸åµŒåˆ—è¡¨
    context = {"code":[],"docs":[],"images":[]}
    for file in uploaded_files:
        parsed_data = parse_uploaded_file(file)
        if parsed_data['type'] == 'code':
            context['code'].append(parsed_data['content'])
        elif parsed_data['type'] == 'image':
            context["images"].append(parsed_data['content'])
        elif parsed_data["type"] == 'document':
            context["docs"].append(parsed_data['content'])

    current_profile = ""
    if os.path.exists(PROFILE_PATH):
        with open(PROFILE_PATH,"r",encoding="utf-8") as f:
            current_profile = f.read()
    else:
        current_profile = "è¿™æ˜¯ç”¨æˆ·ç¬¬ä¸€å‘¨ï¼Œæš‚æ— ä¸ªäººèƒ½åŠ›æ¡£æ¡ˆã€‚"

    return context,current_profile

async def agent_librarian_write(code_list: List[str]) -> str:
    """
    [Librarian - æ¡£æ¡ˆç®¡ç†å‘˜ (å†™æ“ä½œ)]
    èŒè´£ï¼šç›´æ¥è¯»å–æœ¬åœ°æ—§æ¡£æ¡ˆï¼Œå¹¶ç»“åˆæœ¬å‘¨ä¸Šä¼ çš„ã€åŸå§‹ä»£ç ã€‘ï¼Œæ›´æ–° profile.txtã€‚
    å‚æ•°ï¼šcode_list (åŒ…å«æœ¬å‘¨æ‰€æœ‰ä»£ç æ–‡æœ¬çš„åˆ—è¡¨)
    """   

    # è¯»å–æ—§æ¡£æ¡ˆ
    if os.path.exists(PROFILE_PATH):
        with open(PROFILE_PATH, "r", encoding="utf-8") as f:
            old_profile = f.read()
    else:
        old_profile = "ã€æ–°ç”¨æˆ·ã€‘æš‚æ— å†å²æ¡£æ¡ˆã€‚åˆå§‹è¯„çº§ï¼šæœªå®šã€‚"

    #é¢„å¤„ç†ä»£ç å†…å®¹
    raw_code_content = "\n\n--- Next File ---\n\n".join(code_list)
    # if len(raw_code_content) > 50000: 
    #     raw_code_content = raw_code_content[:50000] + "\n...(ä»£ç è¿‡é•¿å·²æˆªæ–­)..."

    system_prompt = """
    ã€ä»»åŠ¡æŒ‡ä»¤ã€‘
    æ ¹æ®æä¾›çš„[æ—§æ¡£æ¡ˆ]ä¸[æœ¬å‘¨åŸå§‹ä»£ç ]ï¼Œå…¨é‡ç”Ÿæˆä¸€ä»½[æ›´æ–°åçš„æŠ€æœ¯æ¡£æ¡ˆ]ã€‚

    ã€å¤„ç†é€»è¾‘ã€‘
    1. **æŠ€èƒ½æå– (åŸºäºäº‹å®)**ï¼šæ‰«æä»£ç ä¸­å®é™…ä½¿ç”¨çš„åº“ (Libraries)ã€æ¡†æ¶ã€è¯­æ³•ç‰¹æ€§åŠè®¾è®¡æ¨¡å¼ã€‚è‹¥å‘ç°æ–°æŠ€èƒ½ï¼Œå°†å…¶åˆå¹¶ä¸é‡å¤åœ°åŠ å…¥æŠ€èƒ½æ ‘ã€‚
    2. **è´¨é‡ç”»åƒæ›´æ–°**ï¼šåˆ†æä»£ç çš„å·¥ç¨‹è´¨é‡ï¼ˆæ³¨é‡Šè§„èŒƒã€å‘½åé£æ ¼ã€æ¨¡å—åŒ–ç¨‹åº¦ã€ç¡¬ç¼–ç æƒ…å†µï¼‰ã€‚æ®æ­¤å®¢è§‚ä¿®æ­£â€œä»£ç é£æ ¼â€ä¸â€œå½“å‰å¼±ç‚¹â€å­—æ®µã€‚
    3. **åŠ¨æ€è¯„çº§**ï¼šä¾æ®æœ¬å‘¨ä»£ç çš„é€»è¾‘å¤æ‚åº¦ä¸å¥å£®æ€§ï¼ŒåŠ¨æ€è°ƒæ•´ç»¼åˆæŠ€æœ¯è¯„çº§ (S/A/B/C)ã€‚
    4. **å½•å…¥åˆ å‡è§„åˆ™**ï¼šä¸å¾—éšæ„åˆ å‡æ—§æ¡£æ¡ˆå†…å®¹ã€‚æ¡£æ¡ˆçš„å†…å®¹é‡å¤æ—¶ï¼Œæ ¹æ®æƒ…å†µå¯ä»¥å¯¹æ¡£æ¡ˆåšå‡ºé€‚å½“ä¿®æ”¹ã€‚
    ã€è¾“å‡ºçº¦æŸã€‘
    1. æ ¼å¼å¿…é¡»ä¸º Markdownã€‚
    2. **ä¸¥ç¦è¾“å‡º**ä»»ä½•å¼€åœºç™½ã€è§£é‡Šè¯­æˆ–ç»“æŸè¯­ã€‚
    3. **ç›´æ¥è¾“å‡º**å®Œæ•´çš„æ¡£æ¡ˆå†…å®¹ã€‚
    """
    
    user_content = f"ã€å½“å‰æ—§æ¡£æ¡ˆã€‘:\n{old_profile}\n\nã€æœ¬å‘¨åŸå§‹ä»£ç å † (Raw Code Data)ã€‘:\n{raw_code_content}"

    model = MODEL_CONFIG["librarian"]

    new_profile_content = ""
    
    #è°ƒç”¨ AI ç”Ÿæˆæ–°æ¡£æ¡ˆ
    try:
        async for chunk in call_ai_chat(model, system_prompt, user_content):
            new_profile_content += chunk
    except Exception as e:
        return f"[æ¡£æ¡ˆæ›´æ–°å¤±è´¥]: {str(e)}"
    
    #å†™å…¥æ–‡ä»¶ (è¦†ç›–æ›´æ–°)
    try:
        with open(PROFILE_PATH, "w", encoding="utf-8") as f:
            f.write(new_profile_content)
        print("[Librarian] profile.txt å·²æ ¹æ®åŸå§‹ä»£ç æ›´æ–°å®Œæ¯•ã€‚")
    except Exception as e:
        return f"[æ–‡ä»¶å†™å…¥é”™è¯¯]: {str(e)}"

    return new_profile_content

async def agent_reviewer(context: Dict) -> AsyncGenerator[str, None]:
    """
    [Reviewer - ä»£ç å®¡è®¡å‘˜]
    èŒè´£ï¼šå®‰å…¨å®¡è®¡ã€Bug æŸ¥æ‰¾ã€æŠ¥é”™åˆ†æã€‚
    ã€å¤šæ¨¡æ€éœ€æ±‚ã€‘ï¼šé«˜ (éœ€è¦çœ‹æŠ¥é”™æˆªå›¾)
    """

    system_prompt = """
    ã€ä»»åŠ¡æŒ‡ä»¤ã€‘
    å¯¹ç”¨æˆ·æä¾›çš„[ä»£ç ç‰‡æ®µ]åŠ[è¿è¡Œæˆªå›¾]æ‰§è¡Œå®‰å…¨ä¸å¥å£®æ€§å®¡è®¡ã€‚

    ã€æ‰§è¡Œé€»è¾‘ã€‘
    1. **è§†è§‰è¯Šæ–­ **ï¼šè‹¥åŒ…å«å›¾ç‰‡ï¼ˆæŠ¥é”™/è¿è¡Œæˆªå›¾ï¼‰ï¼Œä¼˜å…ˆè§£æé”™è¯¯ä¿¡æ¯ï¼Œå¹¶å®šä½ä»£ç ä¸­çš„å…·ä½“è‡´é”™è¡Œã€‚
    2. **å®‰å…¨æ‰«æ**ï¼šæ£€æµ‹å…³é”®æ¼æ´ï¼ˆSQLæ³¨å…¥ã€XSSã€ç¡¬ç¼–ç å¯†é’¥ã€æ•æ„Ÿæ•°æ®æ³„éœ²ã€è¶Šæƒè®¿é—®ï¼‰ã€‚
    3. **å¥å£®æ€§è¯„ä¼°**ï¼šè¯†åˆ«è¿è¡Œæ—¶é£é™©ï¼ˆç©ºæŒ‡é’ˆã€æœªæ•è·å¼‚å¸¸ã€æ­»å¾ªç¯ã€èµ„æºæœªå…³é—­ã€è¯­æ³•é”™è¯¯ï¼‰ã€‚
    4. **ä»£ç å¼‚å‘³**ï¼šæŒ‡å‡ºä¸å¯è¯»å‘½åã€é­”æ³•æ•°å­—ã€å†—ä½™é€»è¾‘æˆ–åæ¨¡å¼å†™æ³•ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘
    å¿…é¡»ä½¿ç”¨ Markdown æ ¼å¼ï¼Œä»…åŒ…å«ä»¥ä¸‹æ¿å—ï¼ˆè‹¥æŸæ¿å—æ— å†…å®¹åˆ™çœç•¥ï¼‰ï¼š
    - **ğŸ”´ è‡´å‘½é—®é¢˜**ï¼š(ä¼šå¯¼è‡´å´©æºƒæˆ–ä¸¥é‡å®‰å…¨æ¼æ´çš„é—®é¢˜)
    - **ğŸŸ¡ æ”¹è¿›å»ºè®®**ï¼š(æ€§èƒ½ä¼˜åŒ–ã€é€»è¾‘ç®€åŒ–ã€ä»£ç è§„èŒƒ)
    - **ğŸ“¸ æˆªå›¾åˆ†æ**ï¼š(é’ˆå¯¹å›¾ç‰‡ä¸­æŠ¥é”™ä¿¡æ¯çš„ç®€è¦æŠ€æœ¯è§£è¯»)
    - **ğŸ’¡ ä¿®å¤ä»£ç **ï¼š(ä»…é’ˆå¯¹æœ€ä¸¥é‡é—®é¢˜æä¾›æœ€å°åŒ–ä¿®å¤ç‰‡æ®µ)

    ã€é£æ ¼çº¦æŸã€‘
    å®¢è§‚ã€ç›´æ¥ã€æŠ€æœ¯å¯¼å‘ã€‚ä¸¥ç¦è¾“å‡ºå¯’æš„è¯­ã€‚
    """
    code_snippets = context.get('code',[])
    image_list = context.get('images',[])

    full_code_text = "\n\n".join(code_snippets)
    if len(full_code_text) > 30000:
        full_code_text = full_code_text[:30000] + "\n\n(ä»£ç è¿‡é•¿ï¼Œåç»­éƒ¨åˆ†å·²æˆªæ–­...)"

    if not full_code_text and not image_list:
        yield"[å®¡è®¡å‘˜]ï¼šæ²¡æœ‰ä»£ç æ–‡æœ¬ä¸æˆªå›¾ï¼Œæœ¬å‘¨å†…å®¹æ— "
        return
    
    user_content = f"ã€å¾…å¤„ç†ä»£ç :ã€‘:\n{full_code_text}"
    if not full_code_text:
        user_content = "ã€ä»£ç å†…å®¹ã€‘: (æ— æ–‡æœ¬ï¼Œä»…åˆ†ææä¾›çš„æˆªå›¾)"

    model = MODEL_CONFIG["reviewer"]

    try:
        async for chunk in call_ai_chat(model,system_prompt,user_content,image_base64_list=image_list):
            yield chunk

    except Exception as e:
        error_msg = f"\n\n[Reviewerè¿è¡Œå‡ºé”™]:{str(e)}"        
        print(error_msg)
        yield error_msg



# è®°å¾—åœ¨æ–‡ä»¶å¤´éƒ¨ç¡®ä¿å¯¼å…¥ï¼š from typing import AsyncGenerator

async def agent_architect(context: Dict) -> AsyncGenerator[str, None]:
    """
    [Architect - æŠ€æœ¯æ¶æ„å¸ˆ]
    èŒè´£ï¼šæ€§èƒ½è¯„ä¼°ã€æŠ€æœ¯æ ˆå¯¹æ¯”ã€æˆé•¿å€¼è®¡ç®—ã€‚
    """
    #è¯»å–æ—§æ¡£æ¡ˆ 
    old_profile = ""
    if os.path.exists(PROFILE_PATH):
        try:
            with open(PROFILE_PATH, "r", encoding="utf-8") as f:
                old_profile = f.read()
        except Exception:
            old_profile = "è¯»å–æ¡£æ¡ˆå‡ºé”™ï¼Œè§†ä¸ºç©ºç™½æ¡£æ¡ˆã€‚"
    else:
        old_profile = "ã€æ–°ç”¨æˆ·ã€‘æš‚æ— å†å²æ¡£æ¡ˆã€‚åˆå§‹è¯„çº§ï¼šæœªå®šã€‚"

    #æå–å¹¶æ¸…æ´—æ•°æ®
    code_snippets = context.get('code', [])
    word_snippets = context.get('docs', [])


    full_code_text = "\n\n".join(code_snippets)
    if len(full_code_text) > 30000:
        full_code_text = full_code_text[:30000] + "\n\n(ä»£ç è¿‡é•¿ï¼Œåç»­éƒ¨åˆ†å·²æˆªæ–­...)"
    
    full_doc_text = "\n\n".join(word_snippets)
    if len(full_doc_text) > 30000:
        full_doc_text = full_doc_text[:30000] + "\n...(æ–‡æ¡£è¿‡é•¿å·²æˆªæ–­)"

    #ç©ºå†…å®¹æ£€æŸ¥
    if not full_code_text and not full_doc_text:
        yield "ã€æ¶æ„å¸ˆã€‘: æœªæ£€æµ‹åˆ°ä»£ç æˆ–æŠ€æœ¯æ–‡æ¡£ï¼Œæ— æ³•è¿›è¡Œæ¶æ„è¯„ä¼°ã€‚"
        return
    
    system_prompt = """
    ã€æŒ‡ä»¤ç›®æ ‡ã€‘
    åŸºäºç”¨æˆ·[æ—§æ¡£æ¡ˆ]ä¸[æœ¬å‘¨ä»£ç /æ–‡æ¡£]ï¼Œæ‰§è¡Œå®è§‚æ¶æ„è¯„ä¼°ä¸æŠ€æœ¯æˆé•¿åˆ¤å®šã€‚å¿½ç•¥å…·ä½“è¯­æ³•é”™è¯¯ï¼Œä¸“æ³¨ä»£ç çš„å¯ç»´æŠ¤æ€§ã€è®¾è®¡é€»è¾‘ã€æŠ€æœ¯ä¸Šé™ä¸è¿è¡Œæ•ˆç‡ï¼ˆé‡ç‚¹ï¼‰ã€‚

    ã€æ‰§è¡Œæ­¥éª¤ã€‘
    1. **æ¶æ„åˆ†æ**ï¼šæå–ä»£ç çš„ç»“æ„æ¨¡å¼ï¼ˆå¦‚åˆ†å±‚ã€æ¨¡å—åŒ–ç¨‹åº¦ï¼‰ã€‚è¯†åˆ«æ˜¯å¦åº”ç”¨äº†ç‰¹å®šè®¾è®¡æ¨¡å¼ï¼ˆOOPã€FPã€å•ä¾‹ã€å·¥å‚ç­‰ï¼‰ï¼Œæ˜¯å¦ä¼˜åŒ–äº†è¿è¡Œæ•ˆç‡ï¼Œè¯„ä¼°æ¶æ„æ€§èƒ½ã€‚
    2. **æˆé•¿æ¯”å¯¹**ï¼šå°†æœ¬å‘¨ä»£ç çš„æŠ€æœ¯æ·±åº¦ä¸[æ—§æ¡£æ¡ˆ]è¿›è¡Œå¯¹æ¯”ã€‚
    - åˆ¤å®šçŠ¶æ€ï¼š**çªç ´**ï¼ˆåº”ç”¨äº†æ–°æ¦‚å¿µ/æ–°æŠ€æœ¯ï¼‰ã€**å·©å›º**ï¼ˆç†Ÿç»ƒåº¦æå‡ï¼‰æˆ– **åœæ»**ï¼ˆé‡å¤ä½æ°´å¹³åŠ³åŠ¨ï¼‰ã€‚
    3. **æŠ€æœ¯æ ˆæå–**ï¼šç½—åˆ—ä»£ç ä¸­ä½¿ç”¨çš„æ ¸å¿ƒæ¡†æ¶ã€ç¬¬ä¸‰æ–¹åº“æˆ–ä¸­é—´ä»¶ã€‚
    4. **ç»¼åˆå®šçº§**ï¼šæ ¹æ®ä»£ç çš„å·¥ç¨‹å¤æ‚åº¦ä¸è®¾è®¡ç¾æ„Ÿæˆ–è€…è¿è¡Œæ•ˆç‡ï¼Œç»™å‡º S/A/B/C è¯„çº§ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘
    ä¸¥æ ¼éµå¾ª Markdown æ ¼å¼ï¼Œä»…è¾“å‡ºä»¥ä¸‹å››ä¸ªæ¿å—ï¼š

    - **ğŸ—ï¸ æ¶æ„æˆ–æ€§èƒ½è§†ç‚¹**ï¼š(ç®€è¿°ä»£ç ç»“æ„ã€æ¨¡å—åˆ’åˆ†åŠè¿è¡Œæ•ˆç‡)
    - **ğŸ“ˆ æˆé•¿è¯„ä¼°**ï¼š(æ˜ç¡®æŒ‡å‡ºä¸æ—§æ¡£æ¡ˆç›¸æ¯”çš„è¿›æ­¥ç‚¹ï¼Œåˆ¤å®šæœ¬å‘¨çŠ¶æ€)
    - **ğŸ› ï¸ æŠ€æœ¯æ ˆä¾¦æµ‹**ï¼š(åˆ—å‡ºæ£€æµ‹åˆ°çš„å…³é”®æŠ€æœ¯/åº“)
    - **âš–ï¸ ç»¼åˆè¯„çº§**ï¼š(ç»™å‡º S/A/B/C è¯„åˆ†å¹¶ç®€è¿°ç†ç”±)
    """
    user_content = f"ã€å½“å‰æ—§æ¡£æ¡ˆã€‘:\n{old_profile}\n\nã€æœ¬å‘¨åŸå§‹ä»£ç å †ã€‘:\n{full_code_text} \n\nã€æœ¬å‘¨æ–‡æ¡£å†…å®¹ã€‘:\n{full_doc_text}"

    model = MODEL_CONFIG["architect"]

    try:
        async for chunk in call_ai_chat(model, system_prompt, user_content):
            yield chunk
    except Exception as e:
        error_msg = f"\n\n[Architect è¿è¡Œå‡ºé”™]: {str(e)}"        
        print(error_msg)
        yield error_msg

async def agent_mentor(review_res: str, architect_res: str, user_note: str,context:Dict) -> AsyncGenerator[str, None]:
    """
    [Mentor - å¯¼å¸ˆ]
    èŒè´£ï¼šæ±‡æ€»æŠ¥å‘Šï¼Œç”Ÿæˆæœ€ç»ˆå‘¨æŠ¥ã€‚
    """
    code_snippets = context.get('code', [])
    system_prompt = """
    ã€æŒ‡ä»¤ç›®æ ‡ã€‘
    åŸºäº[ä»£ç å®¡è®¡æŠ¥å‘Š]ã€[æ¶æ„è¯„ä¼°æŠ¥å‘Š]ã€[å­¦ç”Ÿå¿ƒå¾—]åŠ[å­¦ç”Ÿæºä»£ç ]ï¼Œæ’°å†™ä¸€ä»½ç»¼åˆæ€§çš„ã€Šæœ¬å‘¨æˆé•¿å‘¨æŠ¥ã€‹ã€‚éœ€æ•´åˆå¤šæ–¹ä¿¡æ¯ï¼Œæç‚¼æ ¸å¿ƒè§‚ç‚¹ï¼Œé¿å…å•çº¯å¤è¿°ï¼Œè¦æ±‚çŸ¥è¯†å¯†åº¦é«˜ã€‚

    ã€æ‰§è¡Œé€»è¾‘ã€‘
    1. **æç‚¼é«˜å…‰ (Highlights)**ï¼šä¾æ®æ¶æ„è¯„ä¼°ï¼Œè¯†åˆ«ä»£ç ä¸­çš„è®¾è®¡äº®ç‚¹ã€æ¨¡å¼åº”ç”¨æˆ–ç›¸å¯¹äºæ—§æ¡£æ¡ˆçš„æŠ€æœ¯çªç ´ã€‚
    2. **èšç„¦æ”¹è¿› (Focus Area)**ï¼šä»å®¡è®¡æŠ¥å‘Šä¸­ç­›é€‰å‡ºä¼˜å…ˆçº§é«˜çš„ 2-3 ä¸ªé—®é¢˜ï¼ˆå¦‚ä¸¥é‡å®‰å…¨æ¼æ´ã€æ ¸å¿ƒé€»è¾‘è°¬è¯¯æˆ–æ¶åŠ£çš„ç¼–ç ä¹ æƒ¯ï¼‰ï¼Œä½œä¸ºæœ¬å‘¨æ•´æ”¹é‡ç‚¹ã€‚
    3. **å…¨é‡çº é”™ (Error Analysis)**ï¼šç»¼åˆå®¡è®¡å‘˜ä¸æ¶æ„å¸ˆçš„å‘ç°ï¼Œå¹¶ç»“åˆä½ å¯¹åŸå§‹ä»£ç çš„å®¡æŸ¥ï¼Œç½—åˆ—ä»£ç ä¸­å­˜åœ¨çš„é€»è¾‘é”™è¯¯ä¸æŠ€æœ¯è¯¯åŒºã€‚
    4. **ç­”ç–‘ (Q&A)**ï¼šè‹¥[å­¦ç”Ÿå¿ƒå¾—]ä¸­åŒ…å«å…·ä½“æŠ€æœ¯å›°æƒ‘æˆ–æé—®ï¼Œæä¾›ç®€æ˜è§£ç­”ï¼›è‹¥æ— æé—®ï¼Œåˆ™è·³è¿‡æ­¤æ­¥éª¤ã€‚
    5. **è§„åˆ’ä¸‹ä¸€æ­¥ (Next Step)**ï¼šé’ˆå¯¹æœ¬å‘¨æš´éœ²çš„çŸ­æ¿ï¼Œå¸ƒç½®å…·ä½“çš„ä¸“é¡¹è®­ç»ƒé¢˜ç›®æˆ–æ¨èä¸€ä¸ªæ ¸å¿ƒå­¦ä¹ å…³é”®è¯ã€‚

    ã€è¾“å‡ºæ ¼å¼ã€‘
    ä¸¥æ ¼éµå¾ª Markdown æ ¼å¼ï¼Œè¯­æ°”ä¸“ä¸šä¸”å…·æœ‰æŒ‡å¯¼æ€§ï¼ŒåŒ…å«ä»¥ä¸‹æ¿å—ï¼š
    - ** æœ¬å‘¨é«˜å…‰**
    - ** æ ¸å¿ƒæ”¹è¿›**
    - ** é”™è¯¯æ¸…å•** (æŒ‡å‡ºæ‰€æœ‰å…·ä½“é”™è¯¯ï¼Œåˆ—å‡ºç”¨æˆ·é”™è¯¯çš„ä»£ç ä¸ä¿®æ­£åçš„ä»£ç ï¼ˆæ ¹æ®æƒ…å†µæä¾›å¤šç§è§£æ³•ï¼‰)(ä¸»è¦éƒ¨åˆ†ï¼Œè¦æ±‚è¾“å‡ºé•¿ï¼Œå°½é‡è´´è¿‘è¾“å‡ºä¸Šé™)
    - ** ç­”ç–‘è§£æƒ‘** (è‹¥æ— é—®é¢˜åˆ™çœç•¥)
    - ** è‡ªèº«å¼ºåŒ–** (ç»™å‡ºç”¨æˆ·ä¸‹ä¸€å‘¨å¯ä»¥å»å­¦ä¹ çš„éƒ¨åˆ†ï¼Œæ¯”å¦‚å»çœ‹...çŸ¥è¯†ç‚¹ï¼Œå»åˆ·...çš„é¢˜ç›®)
    """

    user_content = user_content = f"""
    ã€å­¦ç”Ÿå¿ƒå¾—ã€‘: {user_note}
    
    ã€ä»£ç å®¡è®¡æŠ¥å‘Šã€‘:
    {review_res}
    
    ã€æ¶æ„è¯„ä¼°æŠ¥å‘Šã€‘:
    {architect_res}
    
    ã€ä»£ç ç‰‡æ®µæ‘˜è¦ã€‘:
    {code_snippets}
    """

    model = MODEL_CONFIG["mentor"]
    try:
        async for chunk in call_ai_chat(model,system_prompt,user_content):
            yield chunk
    except Exception as e:
        error_msg = f"\n\n[Architect è¿è¡Œå‡ºé”™]: {str(e)}"        
        print(error_msg)
        yield error_msg


# ==========================================
# 4. ä¸»å·¥ä½œæµæ§åˆ¶ (Workflow)
# ==========================================

# async def run_weekly_analysis(uploaded_files, user_note, current_profile):

    
def main():
    # 1. å¿…é¡»æœ€å…ˆæ‰§è¡Œé…ç½®
    st.set_page_config(page_title="AI Coding Mentor", layout="wide", page_icon="ğŸ§™â€â™‚ï¸")
    
    # 2. CSS æ ·å¼ä¼˜åŒ–
    st.markdown("""
    <style>
    .stTextArea textarea { font-size: 16px; }
    div[data-testid="stExpander"] details summary p { font-size: 1.1rem; font-weight: 600; }
    </style>
    """, unsafe_allow_html=True)

    # 3. åˆå§‹åŒ– Session State (é˜²æ­¢åˆ·æ–°ä¸¢å¤±)
    if "analysis_result" not in st.session_state:
        st.session_state.analysis_result = None  

    # --- ä¾§è¾¹æ  ---
    with st.sidebar:
        st.header("ğŸ§™â€â™‚ï¸ ä¸ªäººæ¡£æ¡ˆ")
        if os.path.exists(PROFILE_PATH):
            with open(PROFILE_PATH, "r", encoding="utf-8") as f:
                st.info(f.read())
        else:
            st.warning("æš‚æ— æ¡£æ¡ˆï¼Œè¯·å…ˆè¿›è¡Œä¸€æ¬¡å‘¨æŠ¥åˆ†æã€‚")

        st.divider()
        if st.button("ğŸ—‘ï¸ æ¸…é™¤æ‰€æœ‰æ•°æ®"):
            if os.path.exists(PROFILE_PATH): os.remove(PROFILE_PATH)
            if os.path.exists(HISTORY_PATH): os.remove(HISTORY_PATH)
            st.session_state.analysis_result = None
            st.rerun()

    # --- ä¸»ç•Œé¢ ---
    st.title("AI Coding Mentor")
    st.caption("ä½ çš„ç§äººæŠ€æœ¯æˆé•¿é¡¾é—®å›¢é˜Ÿ")

    # ä½¿ç”¨ Tabs åˆ†ç¦»å·¥ä½œå°ä¸å†å²
    tab_analysis, tab_history = st.tabs(["ğŸš€ æœ¬å‘¨åˆ†æ", "ğŸ“œ å†å²æ¡£æ¡ˆ"])

    # ==========================
    # Tab 1: åˆ†æå·¥ä½œå°
    # ==========================
    with tab_analysis:
        col_input, col_note = st.columns([1, 1])
        with col_input:
            uploaded_files = st.file_uploader("1. ä¸Šä¼ ä»£ç /æ–‡æ¡£", accept_multiple_files=True)
        with col_note:
            user_note = st.text_area("2. æœ¬å‘¨å¿ƒå¾—", height=100, placeholder="ä¾‹å¦‚ï¼šè¿™å‘¨ä¸»è¦å­¦ä¹ äº†...")

        start_btn = st.button("å¯åŠ¨å‘¨æŠ¥åˆ†æ", type="primary", use_container_width=True)
        st.divider()

        # é¢„å…ˆå®šä¹‰å¸ƒå±€å®¹å™¨ï¼ˆé˜²æ­¢UIè·³åŠ¨ï¼‰
        st.subheader("ç¬¬ä¸€é˜¶æ®µï¼šæ·±åº¦æŠ€æœ¯è¯„ä¼°")
        col_review, col_arch = st.columns(2)
        with col_review:
            st.markdown("#### ä»£ç å®¡è®¡ (Reviewer)")
            # ä½¿ç”¨ container å›ºå®šé«˜åº¦ï¼Œç¾è§‚
            review_box = st.container(height=500, border=True)
            review_placeholder = review_box.empty()
        
        with col_arch:
            st.markdown("#### æ¶æ„è¯„ä¼° (Architect)")
            arch_box = st.container(height=500, border=True)
            arch_placeholder = arch_box.empty()

        st.subheader("ç¬¬äºŒé˜¶æ®µï¼šå¯¼å¸ˆæ€»ç»“ (Mentor)")
        mentor_box = st.container(border=True)
        mentor_placeholder = mentor_box.empty()

        # --- æ ¸å¿ƒé€»è¾‘ A: ç‚¹å‡»è¿è¡Œ ---
        if start_btn:
            if not uploaded_files:
                st.error("âš ï¸ è¯·å…ˆä¸Šä¼ æ–‡ä»¶ï¼")
            else:
                # ä½¿ç”¨ st.status æ˜¾ç¤ºè¿›åº¦çŠ¶æ€
                with st.status("ğŸ”¥ AI å›¢é˜Ÿæ­£åœ¨å¹¶è¡Œå·¥ä½œä¸­...", expanded=True) as status:
                    
                    async def run_async_logic():
                        try:
                            # 1. Librarian
                            st.write("Librarian: æ­£åœ¨æ•´ç†æ–‡ä»¶å¹¶æ›´æ–°æ¡£æ¡ˆ...")
                            context, _ = await agent_librarian(uploaded_files)
                            await agent_librarian_write(context['code']) # åå°æ›´æ–°æ¡£æ¡ˆ

                            # 2. Reviewer & Architect å¹¶è¡Œ
                            st.write("Reviewer & Architect: æ­£åœ¨åˆ†æä»£ç ...")
                            
                            # ä¸´æ—¶å­˜å‚¨ç»“æœç”¨äºæ˜¾ç¤º
                            results = {"review": "", "arch": "", "mentor": ""}

                            # å®šä¹‰æµå¼å›è°ƒ
                            async def stream_review():
                                async for chunk in agent_reviewer(context):
                                    results["review"] += chunk
                                    review_placeholder.markdown(results["review"] + "â–Œ")
                                review_placeholder.markdown(results["review"])

                            async def stream_arch():
                                async for chunk in agent_architect(context):
                                    results["arch"] += chunk
                                    arch_placeholder.markdown(results["arch"] + "â–Œ")
                                arch_placeholder.markdown(results["arch"])

                            await asyncio.gather(stream_review(), stream_arch())

                            # 3. Mentor
                            st.write("Mentor: æ­£åœ¨æ’°å†™å‘¨æŠ¥...")
                            async for chunk in agent_mentor(results["review"], results["arch"], user_note, context):
                                results["mentor"] += chunk
                                mentor_placeholder.markdown(results["mentor"] + "â–Œ")
                            mentor_placeholder.markdown(results["mentor"])

                            # 4. ä¿å­˜çŠ¶æ€ä¸æ–‡ä»¶
                            st.session_state.analysis_result = results
                            
                            new_record = {
                                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                                "note": user_note,
                                **results 
                            }
                            
                            history = []
                            if os.path.exists(HISTORY_PATH):
                                try:
                                    with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                                        history = json.load(f)
                                except: pass
                            
                            history.append(new_record)
                            with open(HISTORY_PATH, "w", encoding="utf-8") as f:
                                json.dump(history, f, ensure_ascii=False, indent=2)

                            status.update(label="âœ… åˆ†æå®Œæˆï¼å·²å½’æ¡£", state="complete", expanded=False)
                            st.balloons()
                            
                        except Exception as e:
                            st.error(f"è¿è¡Œå‡ºé”™: {e}")

                    
                    asyncio.run(run_async_logic())

        # --- æ ¸å¿ƒé€»è¾‘ B: å›å¡«æ—§æ•°æ® (é˜²æ­¢åˆ·æ–°ç™½å±) ---
        elif st.session_state.analysis_result:
            res = st.session_state.analysis_result
            review_placeholder.markdown(res["review"])
            arch_placeholder.markdown(res["arch"])
            mentor_placeholder.markdown(res["mentor"])

    # ==========================
    # Tab 2: å†å²æ¡£æ¡ˆ
    # ==========================
    with tab_history:
        if not os.path.exists(HISTORY_PATH):
            st.info("ğŸ“­ æš‚æ— å†å²è®°å½•")
        else:
            try:
                with open(HISTORY_PATH, "r", encoding="utf-8") as f:
                    data = json.load(f)
                
                # å€’åºéå†ï¼ˆæœ€æ–°çš„åœ¨æœ€å‰ï¼‰
                for idx, item in enumerate(reversed(data)):
                    ts = item.get('timestamp', 'Unknown')
                    note = item.get('note', '')[:30]
                    
                    with st.expander(f"ğŸ“… {ts} | å¿ƒå¾—: {note}...", expanded=(idx==0)):
                        t1, t2, t3 = st.tabs(["å¯¼å¸ˆå‘¨æŠ¥", "ä»£ç å®¡è®¡", "æ¶æ„è¯„ä¼°"])
                        with t1: st.markdown(item.get('mentor', ''))
                        with t2: st.markdown(item.get('review', ''))
                        with t3: st.markdown(item.get('arch', ''))
            except Exception as e:
                st.error(f"å†å²è®°å½•è¯»å–å¤±è´¥: {e}")

if __name__ == "__main__":
    main()